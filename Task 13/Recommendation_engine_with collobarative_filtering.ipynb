{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2zxrOuuzsKX",
        "outputId": "71eb29e2-a4e3-46f1-d876-f4e33248e9ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.15.2)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505206 sha256=57a7fc918f7dab631fb25f213e66914c3e8e27f2cacf9a550ca00cd564e42e3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA3Scs_y0bJ-",
        "outputId": "700d2561-6ba7-41c8-eb85-f4c3737967b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def load_data():\n",
        "    movies = pd.read_csv(\"/content/movies.csv\")\n",
        "    ratings = pd.read_csv(\"/content/ratings.csv\")\n",
        "    return movies, ratings\n",
        "\n",
        "def preprocess_data(movies, ratings):\n",
        "    ratings['userId'] = pd.to_numeric(ratings['userId'], errors='coerce')\n",
        "    ratings['movieId'] = pd.to_numeric(ratings['movieId'], errors='coerce')\n",
        "    ratings['rating'] = pd.to_numeric(ratings['rating'], errors='coerce')\n",
        "    movies['genres'] = movies['genres'].str.replace('|', ', ')\n",
        "    ratings = ratings.dropna()\n",
        "    movies = movies.dropna()\n",
        "    return movies, ratings\n",
        "\n",
        "def train_model(ratings):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
        "    algo.fit(trainset)\n",
        "    return algo\n",
        "\n",
        "def get_top_n_recommendations(algo, movies, ratings, user_id, n=20):\n",
        "    all_movie_ids = movies['movieId'].unique()\n",
        "    rated_movies = ratings[ratings['userId'] == user_id]['movieId'].unique()\n",
        "    movies_to_predict = np.setdiff1d(all_movie_ids, rated_movies)\n",
        "    testset = [[user_id, movie_id, 4.] for movie_id in movies_to_predict]\n",
        "    predictions = algo.test(testset)\n",
        "    recs = []\n",
        "    for pred in predictions:\n",
        "        movie_info = movies[movies['movieId'] == pred.iid].iloc[0]\n",
        "        recs.append({\n",
        "            'movieId': pred.iid,\n",
        "            'title': movie_info['title'],\n",
        "            'genres': movie_info['genres'],\n",
        "            'predicted_rating': round(pred.est, 2)\n",
        "        })\n",
        "    return pd.DataFrame(recs).sort_values('predicted_rating', ascending=False)\n",
        "\n",
        "def diversify_recommendations(recommendations, movies, n=10, diversity_weight=0.7):\n",
        "    genres = movies.set_index('movieId')['genres'].str.get_dummies(', ')\n",
        "    genre_matrix = genres.loc[recommendations['movieId']].values\n",
        "    similarity_matrix = cosine_similarity(genre_matrix)\n",
        "    selected_indices = []\n",
        "    remaining_indices = list(range(len(recommendations)))\n",
        "    selected_indices.append(remaining_indices.pop(0))\n",
        "    while len(selected_indices) < n and remaining_indices:\n",
        "        similarities = similarity_matrix[remaining_indices][:, selected_indices]\n",
        "        avg_similarity = similarities.max(axis=1)\n",
        "        diversity_score = 1 - avg_similarity\n",
        "        combined_score = ((1 - diversity_weight) * recommendations.iloc[remaining_indices]['predicted_rating'].values + diversity_weight * diversity_score)\n",
        "        next_index = remaining_indices[np.argmax(combined_score)]\n",
        "        selected_indices.append(next_index)\n",
        "        remaining_indices.remove(next_index)\n",
        "    return recommendations.iloc[selected_indices[:n]]\n",
        "\n",
        "def explain_recommendations(user_id, recommendations, ratings, movies):\n",
        "    user_movies = ratings[ratings['userId'] == user_id]\n",
        "    user_genres = movies[movies['movieId'].isin(user_movies['movieId'])]['genres']\n",
        "    top_genres = user_genres.str.split(', ').explode().value_counts().head(3).index.tolist()\n",
        "    explanations = []\n",
        "    for _, row in recommendations.iterrows():\n",
        "        movie_genres = set(row['genres'].split(', '))\n",
        "        common_genres = list(movie_genres.intersection(top_genres))\n",
        "        if common_genres:\n",
        "            explanation = f\"You like {', '.join(common_genres)} movies\"\n",
        "        else:\n",
        "            top_similar = recommendations[recommendations['movieId'] != row['movieId']].iloc[0]['genres'].split(', ')[0]\n",
        "            explanation = f\"Popular with fans of {top_similar} movies\"\n",
        "        explanations.append(explanation)\n",
        "    recommendations['explanation'] = explanations\n",
        "    return recommendations\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        movies, ratings = load_data()\n",
        "        movies, ratings = preprocess_data(movies, ratings)\n",
        "        if ratings.empty:\n",
        "            raise ValueError(\"No valid ratings found\")\n",
        "        if movies.empty:\n",
        "            raise ValueError(\"No valid movie data found\")\n",
        "        algo = train_model(ratings)\n",
        "        user_id = 1\n",
        "        basic_recs = get_top_n_recommendations(algo, movies, ratings, user_id, n=50)\n",
        "        diverse_recs = diversify_recommendations(basic_recs, movies, n=15)\n",
        "        final_recs = explain_recommendations(user_id, diverse_recs, ratings, movies)\n",
        "        final_recs = final_recs.head(10)\n",
        "        print(final_recs[['title', 'genres', 'predicted_rating', 'explanation']].to_string(index=False))\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p95L2_Rs6mxd",
        "outputId": "8c1ea82d-5b6b-4819-8b75-fa5837576c59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title                         genres  predicted_rating                        explanation\n",
            "                         Boondock Saints, The (2000) Action, Crime, Drama, Thriller              5.00             You like Action movies\n",
            "Spirited Away (Sen to Chihiro no kamikakushi) (2001)  Adventure, Animation, Fantasy              5.00          You like Adventure movies\n",
            "                              His Girl Friday (1940)                Comedy, Romance              5.00             You like Comedy movies\n",
            "                               Little Big Man (1970)                        Western              4.94 Popular with fans of Action movies\n",
            "                                  Hoop Dreams (1994)                    Documentary              4.94 Popular with fans of Action movies\n",
            "                          Maltese Falcon, The (1941)             Film-Noir, Mystery              4.85 Popular with fans of Action movies\n",
            "                                 Interstellar (2014)                   Sci-Fi, IMAX              4.77 Popular with fans of Action movies\n",
            "                                     Suspiria (1977)                         Horror              4.62 Popular with fans of Action movies\n",
            "                         Meet Me in St. Louis (1944)                        Musical              4.62 Popular with fans of Action movies\n",
            "                                              Cosmos             (no genres listed)              4.62 Popular with fans of Action movies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7552669d1eba>:76: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  recommendations['explanation'] = explanations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Pipeline**\n",
        "\n",
        "**Input:**\n",
        "\n",
        "* movies.csv: Movie metadata (ID, title, genres)\n",
        "\n",
        "* ratings.csv: User ratings (userID, movieID, rating 1-5)\n",
        "\n",
        "**Preprocessing:**\n",
        "\n",
        "* Converted IDs/ratings to numeric types and cleaned genres (e.g., \"Adventure|Children\" → \"Adventure, Children\").\n",
        "\n",
        "* Dropped rows with missing values to ensure data quality.\n",
        "\n",
        "-----\n",
        "\n",
        "**2. Model Architecture**\n",
        "\n",
        "* Algorithm: Singular Value Decomposition (SVD)\n",
        "\n",
        "* Chosen for its effectiveness in collaborative filtering and handling sparse data.\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "* n_factors=50: Captures 50 latent features (balances complexity and performance).\n",
        "\n",
        "* n_epochs=20: Trains over 20 iterations for convergence.\n",
        "\n",
        "* Regularization (reg_all=0.02) to prevent overfitting.\n",
        "\n",
        "-----\n",
        "\n",
        "\n",
        "**3. Recommendation Workflow**\n",
        "\n",
        "Step 1: Initial Predictions\n",
        "* For a target user (default: user #1):\n",
        "\n",
        "* Identify movies they haven’t rated.\n",
        "\n",
        "* Predict ratings using the trained SVD model.\n",
        "\n",
        "* Return top 50 movies by predicted rating.\n",
        "\n",
        "Step 2: Diversity Enhancement\n",
        "\n",
        "* Problem: Top predictions often cluster in similar genres (e.g., all action movies).\n",
        "\n",
        "* Solution:\n",
        "Represent movies as genre vectors (e.g., Action=1, Comedy=0).\n",
        "\n",
        "* Use cosine similarity to measure genre overlap.\n",
        "\n",
        "**Select movies that balance:**\n",
        "\n",
        "* High predicted ratings (70% weight).\n",
        "\n",
        "* Genre diversity (30% weight).\n",
        "\n",
        "Step 3: Explanations\n",
        "\n",
        "For each recommendation:\n",
        "\n",
        "* If the movie shares genres the user previously liked:\n",
        "\"You like Comedy and Romance movies.\"\n",
        "\n",
        "* Else: Fallback to \"Popular with fans of [Genre]\" (based on most common genre in top recommendations)."
      ],
      "metadata": {
        "id": "6hYN4-dw9Es2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is a collaborative filtering system enhanced with diversity ranking and explainability (which don’t affect the core CF logic).**"
      ],
      "metadata": {
        "id": "CvB8eBOM-08X"
      }
    }
  ]
}